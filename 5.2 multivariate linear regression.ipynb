{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.2 multivariate linear regression.ipynb","provenance":[],"authorship_tag":"ABX9TyN4XHR9akIbc9U7tW2c3wNd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bPONqfXV6tjV"},"source":["来动手实现一下多元线性回归吧！\r\n","\r\n","1.调用sklearn\r\n","\r\n","2.对代价函数求导，令导数=0。求出W。公式推导见理论课。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGbet7ar6rHO","executionInfo":{"status":"ok","timestamp":1609890861305,"user_tz":-660,"elapsed":1137,"user":{"displayName":"Joan Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXycZOVLnPGAJ6aPtTeURjjA4_peVJdIc9WYTPUA=s64","userId":"03224417507896045947"}},"outputId":"9c0f82ea-2fe4-45e5-8abd-e20cb64d947f"},"source":["import numpy as np\r\n","from sklearn.linear_model import LinearRegression\r\n","\r\n","# 生成样本数据， 特征维度为2\r\n","X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\r\n","# y = 1 * x_0 + 2 * x_1 + 3\r\n","y = np.dot(X, np.array([1, 2])) + 3\r\n","\r\n","# 先使用sklearn自带的库来解决\r\n","model = LinearRegression().fit(X, y)\r\n","\r\n","# 打印参数以及偏移量（bias）\r\n","print (\"基于sklearn的线性回归模型参数为 coef: \", model.coef_, \" intercept: %.5f\" %model.intercept_)\r\n","\r\n","# TODO: 动手实现多元线性回归的参数估计, 把最后的结果放在res变量里。 res[0]存储的是偏移量，res[1:]存储的是模型参数\r\n","X=np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\r\n","res = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.transpose(),X)),X.transpose()),y)\r\n","\r\n","# 打印参数以偏移量（bias）\r\n","print (\"通过手动实现的线性回归模型参数为 coef: \", res[1:], \" intercept: %.5f\"%res[0])"],"execution_count":26,"outputs":[{"output_type":"stream","text":["基于sklearn的线性回归模型参数为 coef:  [1. 2.]  intercept: 3.00000\n","通过手动实现的线性回归模型参数为 coef:  [1. 2.]  intercept: 3.00000\n"],"name":"stdout"}]}]}