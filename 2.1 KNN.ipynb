{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.1KNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWLBcrnuVq5k9AzEkpXTvo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jwpfYdncmB8T"},"source":["# 用sklearn实现KNN代码示例"]},{"cell_type":"code","metadata":{"id":"_fEQ3labv-6d"},"source":["from sklearn import datasets    \r\n","from sklearn.model_selection import train_test_split    \r\n","from sklearn.neighbors import KNeighborsClassifier   \r\n","import numpy as np    \r\n","# 第一个import是用来导入一个样本数据。sklearn库本身已经提供了不少可以用来测试模型的样本数据，所以通过这个模块的导入就可以直接使用这些数据了。 第二个import是用来做数据集的分割，把数据分成训练集和测试集，这样做的目的是为了评估模型。第三个是导入了KNN的模块，是sklearn提供的现成的算法。\r\n","\r\n","iris = datasets.load_iris()    \r\n","X = iris.data    \r\n","y = iris.target    \r\n","print (X, y)\r\n","# 这几行代码是用来导入数据集的。在这里我们导入的数据集叫做iris数据集，也是开源数据中最为重要的数据集之一。这个数据包含了3个类别，所以适合的问题是分类问题。另外，具体数据集的描述可以参考：https://archive.ics.uci.edu/ml/datasets/Iris/ 从print(x,y)结果可以看到X拥有四个特征，并且标签y拥有0，1，2三种不同的值。\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2003)\r\n","#在这里X存储的是数据的特征，y存储的每一个样本的标签或者分类。我们使用 train_test_split来把数据分成了训练集和测试集。主要的目的是为了在训练过程中也可以验证模型的效果。如果没有办法验证，则无法知道模型训练的好坏。\r\n","#这里的random_state就像随机生成器中的seed。通过不同的值采样的训练数据和测试数据是不一样的。设定一个固定的random_state有助于诊断程序本身，因为每次所期待的结果都会一样。\r\n","\r\n","clf = KNeighborsClassifier(n_neighbors=3)    \r\n","clf.fit(X_train, y_train)\r\n","#这部分是KNN算法的主要模块。首先在这里我们定义了一个KNN object，它带有一个参数叫做n_neighbors=3， 意思就是说我们选择的K值是3.\r\n","\r\n","correct = np.count_nonzero((clf.predict(X_test)==y_test)==True)    \r\n","print (\"Accuracy is: %.3f\" %(correct/len(X_test)))\r\n","#这部分的代码主要用来做预测以及计算准确率。计算准确率的逻辑也很简单，就是判断预测和实际值有多少是相等的。如果相等则算预测正确，否则预测失败。"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f9bWrKkxmMhT"},"source":["# 从零开始实现一个KNN算法"]},{"cell_type":"code","metadata":{"id":"5jXjWZKPv9b_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607761278191,"user_tz":-660,"elapsed":949,"user":{"displayName":"Joan Yin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXycZOVLnPGAJ6aPtTeURjjA4_peVJdIc9WYTPUA=s64","userId":"03224417507896045947"}},"outputId":"e42be727-4f81-4046-eb2a-af2fc6feca30"},"source":["from sklearn import datasets\r\n","from collections import Counter  # 为了做投票\r\n","from sklearn.model_selection import train_test_split\r\n","import numpy as np\r\n","\r\n","# 导入iris数据\r\n","iris = datasets.load_iris()\r\n","X = iris.data\r\n","y = iris.target\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2003)\r\n","\r\n","\r\n","def euc_dis(instance1, instance2):\r\n","    \"\"\"\r\n","    计算两个样本instance1和instance2之间的欧式距离\r\n","    instance1: 第一个样本， array型\r\n","    instance2: 第二个样本， array型\r\n","    \"\"\"\r\n","    # TODO\r\n","    dist = np.sqrt(np.sum((instance1-instance2)**2))\r\n","    return dist\r\n","    \r\n","    \r\n","def knn_classify(X, y, testInstance, k):\r\n","    \"\"\"\r\n","    给定一个测试数据testInstance, 通过KNN算法来预测它的标签。 \r\n","    X: 训练数据的特征\r\n","    y: 训练数据的标签\r\n","    testInstance: 测试数据，这里假定一个测试数据 array型\r\n","    k: 选择多少个neighbors? \r\n","    \"\"\"\r\n","    # TODO  返回testInstance的预测标签 = {0,1,2}\r\n","\r\n","    # 计算 testInstance 与 X的距离\r\n","    dists=[euc_dis(x,testInstance) for x in X]\r\n","   \r\n","    # 找出最近的K个元素的idx\r\n","    idxknn= np.argsort(dists)[:k] #将dists从小到大排序，返回排序后的元素indices\r\n","\r\n","    # 找出KNN对应的n个y值\r\n","    yknn=y[idxknn]\r\n","\r\n","    # 返回投票结果\r\n","    return Counter(yknn).most_common(1)[0][0]\r\n","\r\n","\r\n","# 预测结果。    \r\n","predictions = [knn_classify(X_train, y_train, data, 3) for data in X_test]\r\n","correct = np.count_nonzero((predictions==y_test)==True)\r\n","print (\"Accuracy is: %.3f\" %(correct/len(X_test)))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Accuracy is: 0.921\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RO7Vq046mAPU"},"source":[""]}]}